---
title: "My Spotify Wrapped"
author: "Kaiqi Chen"
output:
  revealjs::revealjs_presentation:
    theme: night
    highlight: zenburn
    center: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(ggplot2); library(lazerhawk); library(plotly); library(dygraphs)
library(dplyr); library(gganimate); library(ggthemes); library(visibly)

# The lazerhawk and visibly packages are from github:
# devtools::install_github('m-clark/lazerhawk')
# devtools::install_github('m-clark/visibly')

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

```{r, message = FALSE, include=FALSE}
library(tidyverse)
library(plotly)
library(ggplot2)
library(gridExtra)
library(pwr)
library(corrplot)
library(DMwR)
library(InformationValue)
library(caret)
```


## The data

- My yearly Spotify Wrapped from 2016-2019, include audio features and track popularity.

- My saved songs in Spotify, include audio features, track and artist popularity, and whether they are in my Wrapped playlists

```{r, message=FALSE}
saved_songs_og <- read_csv('Kaiqi-saved.csv')
wrapped_features_og <- read_csv('wrapped_features.csv')
```

```{r}
saved_songs <- saved_songs_og %>% 
  mutate(key = as.factor(key),
         mode = as.factor(mode),
         wrapped = as.factor(wrapped))
  
saved_songs <- saved_songs %>%
  select(-type, -uri)

wrapped <- wrapped_features_og %>% 
  select(-time_signature, -type, -uri) %>% 
  mutate(key = as.factor(key), wrapped_year = as.factor(wrapped_year))
```


## Visualize My Spotify Wrapped 2016-2019

It seems I listen to slightly more higher energy songs in 2018.
```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
p1 <- wrapped %>% 
  select(energy, liveness, tempo, speechiness, 
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 4,scales = 'free')+
  theme(legend.position = 'none')+
  theme_minimal()

p2 <- wrapped %>% 
  select(energy, liveness, tempo, speechiness, 
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_violin(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 4,scales = 'free')+
  theme(legend.position = 'none')+
  theme_minimal()

grid.arrange(p1,p2, ncol = 1)
```

## 
```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
p3 <- wrapped %>% 
  select(acousticness, instrumentalness, danceability, loudness, valence,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 5,scales = 'free')+
  theme(legend.position = "none")+
  theme_minimal()

p4 <- wrapped %>% 
  select(acousticness, instrumentalness, danceability, loudness, valence,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_violin(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 5,scales = 'free')+
  theme(legend.position = "none")+
  theme_minimal()

grid.arrange(p3,p4, ncol = 1)
```


## Track Popularity

```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
wrapped %>% 
  select(track_popularity,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value))+
  facet_wrap(~key, ncol = 2,scales = 'free')+
  theme_minimal()
```

Track popularity remains about the same each year. A good portion of them are on the popular side in 2017, 2018, 2019.
</br>
</br>

##
Overall, no visualy huge changes in preference.

## It's very tempting to do ANOVA test, but

```{r}
pwr.anova.test(k=4,n=NULL, f=0.1, sig.level = 0.05, power = 0.8)
```

For a small effect size, we need 274 songs for each year.

## Build a model

I wonder if I can build a model to determine whether a song I saved to my library will become one of my top song at the end of the year.



##
```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
saved_songs %>%
  keep(is.numeric) %>%
  gather() %>%
  ggplot() +
  geom_histogram(mapping = aes(x=value,fill=key), color="black", show.legend = FALSE) +
  facet_wrap(~ key, scales = "free") +
  theme_minimal()
```

Duration, instrumentalness, liveness, speechiness and time_signature are probably not very useful.



## Categorical Variables
```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
saved_songs %>%
  keep(is.factor) %>%
  gather() %>%
  group_by(key,value) %>% 
  summarise(n = n()) %>% 
  ggplot() +
  geom_bar(mapping=aes(x = value, y = n, fill=key), color="black", stat='identity') + 
  coord_flip() +
  facet_wrap(~ key, scales = "free") +
  theme_minimal()
```

The dependent variable is very imbalanced.




```{r}
saved_songs <- saved_songs %>% 
  select(energy, tempo, acousticness, danceability, key, loudness, valence, mode,
         artistPopularity, trackPopularity, wrapped)
```



## Correlations
```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
saved_songs %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()
```

Drop loudness, acousticness, and valence


## 
```{r}
saved_songs1 <- saved_songs %>% 
  select(-loudness, -acousticness, -valence)

saved_songs1 %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()
```




Since my data is imbalanced, balace it before running models.</br>
```{r}
set.seed(6666)
songs_balance <- SMOTE(wrapped ~ energy+tempo+danceability+artistPopularity+trackPopularity, data.frame(saved_songs1), perc.over = 100, perc.under = 200)
```

## Bivariate relationships

```{r,fig.height = 5.5, fig.width = 10.5, fig.align="center"}
p1 <- songs_balance %>% 
  mutate(energy = energy) %>% 
  ggplot(aes(energy, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p2 <- songs_balance %>% 
  ggplot(aes(tempo, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p3 <- songs_balance %>% 
  ggplot(aes(danceability, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p4 <- songs_balance %>% 
  ggplot(aes(trackPopularity, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p5 <- songs_balance %>% 
  ggplot(aes(artistPopularity, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

grid.arrange(p1,p2,p3,p4,p5, ncol = 2)
```

It is very easy to see whether each variable has effect.


##
```{r}
logit_mod1 <-
  glm(wrapped ~ tempo+energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs_balance)
summary(logit_mod1)
```

Tempo is not a significant variable, remove it.

##
```{r}
logit_mod2 <-
  glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs_balance)
summary(logit_mod2)
```

##
```{r}
exp(coef(logit_mod2))
```


## Machine learning approach to evaluate the performance

```{r, include=FALSE}
set.seed(1234)
sample.set <- createDataPartition(saved_songs1$wrapped, p = 0.75, list = FALSE)
songs.train <- saved_songs1[sample.set, ]
songs.train <- SMOTE(wrapped ~ ., data.frame(saved_songs1), perc.over = 100, perc.under = 200)
songs.test <- saved_songs1[-sample.set, ]
```

```{r}
logit_mod3 <-
  glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs.train)
summary(logit_mod3)
```


##
```{r}
exp(coef(logit_mod2))
```

## Ideal cutoff
```{r}
logit_pred <- predict(logit_mod3, songs.test, type = 'response')
ideal_cutoff <-
  optimalCutoff(
    actuals = songs.test$wrapped,
    predictedScores = logit_pred,
    optimiseFor = "Both"
  )

ideal_cutoff
```

## Evaluate Performance
```{r}
logit_pred <- ifelse(logit_pred > ideal_cutoff, 1, 0)
logit.matrix <-confusionMatrix(as.factor(logit_pred), songs.test$wrapped, positive = '1')
logit.matrix

accuracy <- as.numeric(logit.matrix$overall["Accuracy"])
accuracy
kappa <- as.numeric(logit.matrix$overall["Kappa"])
kappa
```

Even though the accuracy is not bad, the Kappa is very low. A lot of the correct predictions are probably made just by chance.
</br>

## Bayesian Logistic Regression


```{r, message = FALSE, include=FALSE}
library(rstanarm)
```

```{r}
bLog = stan_glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, data = songs_balance, family = binomial,
              prior = student_t(df = 5, location = 0, scale = 2.5), 
              prior_intercept = student_t(df = 5, location = 0, scale = 2.5), 
              seed = 10001, chains = 6,
              cores = (parallel::detectCores() - 1),
              iter = 4000)

summary(bLog)
```


## Posterior intervals:

```{r}
posterior_interval(bLog, prob = 0.95, pars = c('energy', 'danceability', 'artistPopularity','trackPopularity'))
```



## More to do

1. Bootstrapping on GLM, compare CIs with Bayesian CIs.

2. Improve both accuracy and fututure performance.

3. Mixed model or interactions are worth exploring, but require more data

4. Gather other users data, and see how the models differ.

5. Build something that can generalize to different users of Spotify





