---
title: "Advanced Inference Final Proj-My Spotify Wrapped"
author: "Kaiqi Chen"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
fig_width: 7 
fig_height: 7     

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE}
library(tidyverse)
library(plotly)
library(ggplot2)
library(gridExtra)
library(pwr)
library(corrplot)
library(DMwR)
library(InformationValue)
library(caret)
```

```{r, message=FALSE}
saved_songs_og <- read_csv('Kaiqi-saved.csv')
wrapped_features_og <- read_csv('wrapped_features.csv')
```

### The data

The data is obtained by utilizing the Python Spotipy package. There are two set of data, one is my yearly Spotify Wrapped playlists from 2016-2019. It contains audio information about the track and the track popularity. It is mainly used to visualize how my preference change over the years. Second dataset, Kaiqi-saved, is my spotify saved library, in addition to the variables in wrapped dataset, I also included artist popularity and genres. An dummy variable called "wrapped" indicates whether a song ended up in my year end wrapped playlist. The saved dataset is used to model how the tracks' features influence the odds the tracks being in my wrapped playlist.


```{r}
saved_songs <- saved_songs_og %>% 
  mutate(key = as.factor(key),
         mode = as.factor(mode),
         wrapped = as.factor(wrapped))
  
saved_songs <- saved_songs %>%
  select(-type, -uri)

wrapped <- wrapped_features_og %>% 
  select(-time_signature, -type, -uri) %>% 
  mutate(key = as.factor(key), wrapped_year = as.factor(wrapped_year))
```


### Visualize My Spotify Wrapped 2016-2019

Let's see how my preference change over the past 4 years
</br>
```{r}
p1 <- wrapped %>% 
  select(energy, liveness, tempo, speechiness, 
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 4,scales = 'free')+
  theme(legend.position = 'none')+
  theme_minimal()

p2 <- wrapped %>% 
  select(energy, liveness, tempo, speechiness, 
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_violin(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 4,scales = 'free')+
  theme(legend.position = 'none')+
  theme_minimal()

grid.arrange(p1,p2, ncol = 1)
```



It seems I listen to slightly more higher energy songs in 2018.
</br>

```{r}
p3 <- wrapped %>% 
  select(acousticness, instrumentalness, danceability, loudness, valence,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 5,scales = 'free')+
  theme(legend.position = "none")+
  theme_minimal()

p4 <- wrapped %>% 
  select(acousticness, instrumentalness, danceability, loudness, valence,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_violin(mapping = aes(wrapped_year, value, fill = key), show.legend = FALSE)+
  facet_wrap(~key, ncol = 5,scales = 'free')+
  theme(legend.position = "none")+
  theme_minimal()

grid.arrange(p3,p4, ncol = 1)
```

Seems I was not in the mood of dancing in 2017. And the quieter songs I listening to is getting fewer and fewer. Valence , a measure of music positivity, has a higher mode in 2018.
</br>

```{r}
wrapped %>% 
  select(track_popularity,
        wrapped_year) %>% 
  pivot_longer(-wrapped_year, names_to = 'key', values_to = 'value') %>% 
  ggplot()+
  geom_boxplot(mapping = aes(wrapped_year, value))+
  facet_wrap(~key, ncol = 2,scales = 'free')+
  theme_minimal()
```

Track popularity remains about the same each year. A good portion of them are on the popular side in 2017, 2018, 2019.
</br>
</br>
Overall, visualy, there is no big taste change for my top 100 songs across the years.
</br>
There might be some slight changes, but are they statistically significant?
</br>

Before we start doing ANOVA tests, let's run some power analysis

```{r}
pwr.anova.test(k=4,n=NULL, f=0.1, sig.level = 0.05, power = 0.8)
```

For a small effect size, we need 274 songs for each year. Now that I learned how to interact withj Spotify API, looks like I need to get my own top 300 list at the end of each year from now on.


### Build a model

Since Spotify gave me the top songs for the past four years, and most of my top songs come from my saved songs library. I wonder if I can build a model to determine whether a song I saved to my library will become one of my top song at the end of the year.

```{r}
saved_songs %>%
  keep(is.numeric) %>%
  gather() %>%
  ggplot() +
  geom_histogram(mapping = aes(x=value,fill=key), color="black") +
  facet_wrap(~ key, scales = "free") +
  theme_minimal()
```

Duration, instrumentalness, liveness, speechiness and time_signature are probably not very useful. To me, when I listen to music, I don't care about duration. I don't listen to a lot of pure instrumental music, or live music. And speechiness is very useful to distinguish podcast, talk shows or audio books, but not music. For time_signature, 4 minutes just dominates other durations.

```{r}
saved_songs %>%
  keep(is.factor) %>%
  gather() %>%
  group_by(key,value) %>% 
  summarise(n = n()) %>% 
  ggplot() +
  geom_bar(mapping=aes(x = value, y = n, fill=key), color="black", stat='identity') + 
  coord_flip() +
  facet_wrap(~ key, scales = "free") +
  theme_minimal()
```

The dependent variable is very imbalanced.

```{r}
saved_songs <- saved_songs %>% 
  select(energy, tempo, acousticness, danceability, key, loudness, valence, mode,
         artistPopularity, trackPopularity, wrapped)
```

```{r}
saved_songs %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()
```

Drop loudness, acousticness, and valence

```{r}
saved_songs1 <- saved_songs %>% 
  select(-loudness, -acousticness, -valence)

saved_songs1 %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()
```


Since my data is imbalanced, balace it before running models.</br>
```{r}
set.seed(6666)
songs_balance <- SMOTE(wrapped ~ energy+tempo+danceability+artistPopularity+trackPopularity, data.frame(saved_songs1), perc.over = 100, perc.under = 200)
```

Visualize bivariate relationship between my independent variables and dependent variable.

```{r}
p1 <- songs_balance %>% 
  mutate(energy = energy) %>% 
  ggplot(aes(energy, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p2 <- songs_balance %>% 
  ggplot(aes(tempo, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p3 <- songs_balance %>% 
  ggplot(aes(danceability, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p4 <- songs_balance %>% 
  ggplot(aes(trackPopularity, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

p5 <- songs_balance %>% 
  ggplot(aes(artistPopularity, wrapped))+
    geom_point(size = 1.2, alpha = 0.1)+
    theme_minimal()

grid.arrange(p1,p2,p3,p4,p5, ncol = 2)
```

It is very easy to see whether each variable has effect. Lets model it using GLM.

```{r}
logit_mod1 <-
  glm(wrapped ~ tempo+energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs_balance)
summary(logit_mod1)
```

Tempo is not a significant variable, remove it.

```{r}
logit_mod2 <-
  glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs_balance)
summary(logit_mod2)
```


```{r}
exp(coef(logit_mod2))
```

Now I have a pretty significant model. It seems energy and artistPopularity has some negative effect in the odds of being my top song. Holding other variable constant, for every unit increase in energy, the odds being my top song decrease by 63%. And for every unit increase in artist popularity, the odds of the song being my top song decrease by 2%. And danceability and trackPopularity do increase the odd of being my top song. 
</br>
Even I don't want to admit it, my model says I like danceable and popular songs. And it say I don't like high energy song and popular artists.
</br>

### Machine learning approach to evaluate the performance

Since R^2 is not supported in logistic regression, and the package of getting pseudo R^2 is not recommended. Let's use a machine learning apporoach to evaluate the accuracy.

create training and test datasets
```{r}
set.seed(1234)
sample.set <- createDataPartition(saved_songs1$wrapped, p = 0.75, list = FALSE)
songs.train <- saved_songs1[sample.set, ]
songs.train <- SMOTE(wrapped ~ ., data.frame(saved_songs1), perc.over = 100, perc.under = 200)
songs.test <- saved_songs1[-sample.set, ]
```

```{r}
logit_mod3 <-
  glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, family = binomial(link = 'logit'), data = songs.train)
summary(logit_mod3)
```

```{r}
exp(coef(logit_mod2))
```

Similar result.

Now let's find the optimal cutoff

```{r}
logit_pred <- predict(logit_mod3, songs.test, type = 'response')
ideal_cutoff <-
  optimalCutoff(
    actuals = songs.test$wrapped,
    predictedScores = logit_pred,
    optimiseFor = "Both"
  )

ideal_cutoff
```

Let's evaluate the performance</br>
```{r}
logit_pred <- ifelse(logit_pred > ideal_cutoff, 1, 0)
logit.matrix <-confusionMatrix(as.factor(logit_pred), songs.test$wrapped, positive = '1')
logit.matrix

accuracy <- as.numeric(logit.matrix$overall["Accuracy"])
accuracy
kappa <- as.numeric(logit.matrix$overall["Kappa"])
kappa
```

Even though the accuracy is not bad, the Kappa is very low. A lot of the correct predictions are probably made just by chance.
</br>

### Bayesian Logistic Regression

Let's use Bayesian Data Analysis
```{r, message = FALSE}
library(rstanarm)
```

```{r}
bLog = stan_glm(wrapped ~ energy+danceability+artistPopularity+trackPopularity, data = songs_balance, family = binomial,
              prior = student_t(df = 5, location = 0, scale = 2.5), 
              prior_intercept = student_t(df = 5, location = 0, scale = 2.5), 
              seed = 10001, chains = 6,
              cores = (parallel::detectCores() - 1),
              iter = 4000)

summary(bLog)
```

The mean of the coefficients are similar to GLM results. And the Rhat is also very good. 
</br>
Check out posterior intervals:

```{r}
posterior_interval(bLog, prob = 0.95, pars = c('energy', 'danceability', 'artistPopularity','trackPopularity'))
```

None of them crosses zero, a good sign.
</br>
I do have a strong preferance of dancable songs. However, not a good dancer.
</br>

### More to do

1. Do bootstrapping on GLM and see how bootstrapping CI for the coefficients differ from Bayesian CIs.
</br>
</br>
2. Even though the model has good accuracy. There is still room to improve both accuracy and fututure performance. Try some machine learning algorithms such as decision tree, random forest or AdaBoost.
</br>
</br>
3. Mixed model or interactions are worth exploring, but I need more data of myself to have good result.
</br>
</br>
4. Gather other users data, and see how the models differ.
</br>
</br>
5. Build something that can generalize to different users on Spotify





